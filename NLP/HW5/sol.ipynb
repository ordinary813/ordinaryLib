{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ordinary/ordinaryLib/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "import os, torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset_path = 'imdb_subset'\n",
    "# if the path exists - load the dataset from disk, otherwise download it\n",
    "if os.path.exists(dataset_path):\n",
    "    subset = load_from_disk(dataset_path)\n",
    "else:\n",
    "    dataset = load_dataset('imdb')\n",
    "    subset = dataset['train'].shuffle(seed=42).select(range(500))\n",
    "    subset.save_to_disk('imdb_subset')\n",
    "\n",
    "dataset = subset\n",
    "dataset = dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 240\n",
      "Eval size: 160\n",
      "Test size: 100\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Train test split\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]\n",
    "\n",
    "# Train eval split\n",
    "split_dataset = train_dataset.train_test_split(test_size=0.4, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "# Apply the tokenization function to the datasets\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format for PyTorch\n",
    "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_eval.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Confirm dataset sizes\n",
    "print(f\"Train size: {len(tokenized_train)}\")\n",
    "print(f\"Eval size: {len(tokenized_eval)}\")\n",
    "print(f\"Test size: {len(tokenized_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ordinary/ordinaryLib/myenv/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",               # Directory to save model checkpoints\n",
    "    evaluation_strategy=\"epoch\",          # Evaluate at the end of each epoch\n",
    "    learning_rate=2e-5,                   # Learning rate\n",
    "    per_device_train_batch_size=8,        # Batch size for training\n",
    "    per_device_eval_batch_size=8,         # Batch size for evaluation\n",
    "    num_train_epochs=10,                  # Number of epochs\n",
    "    weight_decay=0.01,                    # Weight decay\n",
    "    logging_dir=\"./logs\",                 # Directory to save logs\n",
    "    logging_steps=10,                     # Log every 10 steps\n",
    "    save_total_limit=2                    # Limit the number of saved checkpoints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3705/3864364326.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)  # Get the index of the max logit\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                          # The pre-trained model to fine-tune\n",
    "    args=training_args,                   # Training arguments\n",
    "    train_dataset=tokenized_train,        # Training dataset\n",
    "    eval_dataset=tokenized_eval,          # Evaluation dataset\n",
    "    tokenizer=tokenizer,                  # Tokenizer for data preprocessing\n",
    "    compute_metrics=compute_metrics       # Custom metrics function\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 01:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.632325</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.484200</td>\n",
       "      <td>0.371623</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.399790</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.820477</td>\n",
       "      <td>0.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.445779</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.412153</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.572372</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.463248</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.484999</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.508464</td>\n",
       "      <td>0.868750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.179014040765663, metrics={'train_runtime': 73.9767, 'train_samples_per_second': 32.443, 'train_steps_per_second': 4.055, 'total_flos': 631466532864000.0, 'train_loss': 0.179014040765663, 'epoch': 10.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test dataset\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "\n",
    "# Extract predicted logits and labels\n",
    "logits = predictions.predictions\n",
    "predicted_labels = np.argmax(logits, axis=1)  # Get the indices of the max logits\n",
    "true_labels = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "positive_reviews = dataset.filter(lambda example: example[\"labels\"] == 1).select(range(100))\n",
    "negative_reviews = dataset.filter(lambda example: example[\"labels\"] == 0).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Reviews\n",
    "def tokenize_reviews(dataset, tokenizer, max_length=150):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples['text'],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_save_GPT2(model, tokenizer, tokenized_dataset, prompt='The movie was'):\n",
    "    # Check which dataset we are training on\n",
    "    if tokenized_dataset[\"labels\"][0] == 0:\n",
    "        sentiment = \"negative\"\n",
    "    elif tokenized_dataset[\"labels\"][0] == 1:\n",
    "        sentiment = \"positive\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./gpt2-{sentiment}-results\",\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,  # batch size per device during training\n",
    "        per_device_eval_batch_size=4,   # batch size for evaluation\n",
    "        weight_decay=0.01,              # strength of weight decay\n",
    "        logging_dir='./logs',      # directory for storing logs\n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False\n",
    "    )\n",
    "\n",
    "    train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "    train_dataset = train_test_split[\"train\"]\n",
    "    eval_dataset = train_test_split[\"test\"]\n",
    "    \n",
    "    # Create a Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    results = trainer.evaluate()\n",
    "    print(f'Perplexity: {results[\"eval_loss\"]}')\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    save_directory = f\"./gpt2-{sentiment}-results\"\n",
    "    trainer.save_model(save_directory)\n",
    "    tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "\n",
    "tokenized_positive_reviews = tokenize_reviews(positive_reviews, gpt2_tokenizer)\n",
    "tokenized_negative_reviews = tokenize_reviews(negative_reviews, gpt2_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3705/4217484498.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.824700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.720800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.714200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.594500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.622200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.466200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.533400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 3.7762298583984375\n"
     ]
    }
   ],
   "source": [
    "train_save_GPT2(gpt2_model, gpt2_tokenizer, tokenized_positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3705/4217484498.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:08, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.815300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.758700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.695500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.549600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.549300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.401100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.552200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.362800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.534300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 3.662398099899292\n"
     ]
    }
   ],
   "source": [
    "train_save_GPT2(gpt2_model, gpt2_tokenizer, tokenized_negative_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_model = GPT2LMHeadModel.from_pretrained(\"gpt2-positive-results\")\n",
    "positive_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-positive-results\")\n",
    "\n",
    "negative_model = GPT2LMHeadModel.from_pretrained(\"gpt2-negative-results\")\n",
    "negative_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-negative-results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Parameters for text generation\n",
    "max_length = 150\n",
    "temperature = 0.7\n",
    "top_k = 50\n",
    "top_p = 0.9\n",
    "repetition_penalty = 1.2\n",
    "prompt = 'The movie was'\n",
    "\n",
    "input_ids_pos = positive_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "attention_mask = input_ids_pos.ne(positive_tokenizer.pad_token_id) \n",
    "\n",
    "input_ids_neg = negative_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "attention_mask = input_ids_neg.ne(negative_tokenizer.pad_token_id)\n",
    "\n",
    "def generate_reviews(model, tokenizer, num_reviews=5):\n",
    "    reviews = []\n",
    "    for _ in range(num_reviews):\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        attention_mask = input_ids.ne(tokenizer.pad_token_id)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model.generate(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=max_length,\n",
    "                temperature=temperature,\n",
    "                top_k=top_k,\n",
    "                top_p=top_p,\n",
    "                repetition_penalty=repetition_penalty,\n",
    "                do_sample=True,\n",
    "                num_return_sequences=1\n",
    "            )\n",
    "        review = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        reviews.append(review)\n",
    "    return reviews\n",
    "\n",
    "positive_reviews = generate_reviews(positive_model, positive_tokenizer)\n",
    "negative_reviews = generate_reviews(negative_model, negative_tokenizer)\n",
    "\n",
    "with open('generated_reviews.txt', 'w') as file:\n",
    "    file.write(\"Reviews generated by positive model:\\n\")\n",
    "    for i, review in enumerate(positive_reviews, start=1):\n",
    "        file.write(f\"{i}. {review}\\n\")\n",
    "    file.write(\"\\nReviews generated by negative model:\\n\")\n",
    "    for i, review in enumerate(negative_reviews, start=1):\n",
    "        file.write(f\"{i}. {review}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - flan-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "flan_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "flan_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "sampled_reviews = random.sample(list(dataset), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_prompt(review_text):\n",
    "    prompt = f\"Classify the following review as positive or negative: \\\"{review_text}\\\"\"\n",
    "    return prompt\n",
    "\n",
    "few_shot_examples = \"\"\"\n",
    "Review 1: \"The movie was fantastic and full of unexpected turns.\" -> positive\n",
    "Review 2: \"The movie was boring and I didn't enjoy it.\" -> negative\n",
    "\"\"\"\n",
    "\n",
    "def few_shot_prompt(review_text):\n",
    "    prompt = few_shot_examples + f\"\\nReview: \\\"{review_text}\\\" ->\"\n",
    "    return prompt\n",
    "\n",
    "def instruction_prompt(review_text):\n",
    "    prompt = f\"Analyze the sentiment of the following review: \\\"{review_text}\\\". Respond with 'positive' or 'negative'.\"\n",
    "    return prompt\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_length=20):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    output = model.generate(**inputs, max_length=max_length, num_beams=5)\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "output_file = 'flan_t5_imdb_results.txt'\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for i, review in enumerate(sampled_reviews):\n",
    "        review_text = review['text']\n",
    "        true_label = review['labels']  # Assuming label is in dataset, 0=negative, 1=positive\n",
    "        true_label_text = \"positive\" if true_label == 1 else \"negative\"\n",
    "        \n",
    "        # Zero-shot\n",
    "        zero_shot = generate_response(zero_shot_prompt(review_text), flan_model, flan_tokenizer)\n",
    "        \n",
    "        # Few-shot\n",
    "        few_shot = generate_response(few_shot_prompt(review_text), flan_model, flan_tokenizer)\n",
    "        \n",
    "        # Instruction-based\n",
    "        instruction_based = generate_response(instruction_prompt(review_text), flan_model, flan_tokenizer)\n",
    "        \n",
    "        # Writing to file\n",
    "        f.write(f\"Review {i+1}: {review_text}\\n\")\n",
    "        f.write(f\"Review {i+1} true label: {true_label_text}\\n\")\n",
    "        f.write(f\"Review {i+1} zero-shot: {zero_shot}\\n\")\n",
    "        f.write(f\"Review {i+1} few-shot: {few_shot}\\n\")\n",
    "        f.write(f\"Review {i+1} instruction-based: {instruction_based}\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
