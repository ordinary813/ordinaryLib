{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from math import log\n",
    "\n",
    "def generate_ngrams(text, n):\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        return [' '.join(words[i:i + n]) for i in range(len(words) - n + 1)]\n",
    "\n",
    "def compute_idf(corpus_collocations, total_docs):\n",
    "    idf_scores = {}\n",
    "    doc_counts = {}\n",
    "\n",
    "    # Count the number of documents containing each collocation\n",
    "    for doc_collocations in corpus_collocations:\n",
    "        unique_collocations = set(doc_collocations)  # Ensure unique collocations per document\n",
    "        for collocation in unique_collocations:\n",
    "            doc_counts[collocation] = doc_counts.get(collocation, 0) + 1\n",
    "\n",
    "    # Compute IDF for each collocation\n",
    "    for collocation, doc_count in doc_counts.items():\n",
    "        idf_scores[collocation] = log(total_docs / (1 + doc_count))\n",
    "\n",
    "    return idf_scores\n",
    "\n",
    "\n",
    "def compute_tf(doc_collocations, collocations):\n",
    "    total_count = len(doc_collocations)\n",
    "    tf_scores = {coll: doc_collocations.count(coll) / total_count for coll in collocations}\n",
    "    return tf_scores\n",
    "\n",
    "def compute_tfidf(tf_scores, idf_scores):\n",
    "    return {coll: tf * idf_scores.get(coll, 0) for coll, tf in tf_scores.items()}\n",
    "\n",
    "# def compute_tfidf(collocations, doc_collocations, total_docs):\n",
    "#         tfidf_scores = {}\n",
    "#         for collocation in collocations:\n",
    "#             tf = doc_collocations.count(collocation) / len(doc_collocations)\n",
    "#             idf = log(total_docs / 1 + sum(collocation in doc for doc in doc_collocations))\n",
    "#             tfidf_scores[collocation] = tf * idf\n",
    "#         return tfidf_scores\n",
    "\n",
    "# Input: \n",
    "#   corpus_df: a dataframe containing the corpus' data\n",
    "#   k: number of top collocations\n",
    "#   n: length of collocations\n",
    "#   t: min threshold for the amount of collocations\n",
    "# Output:\n",
    "#   collocation:grade list from the corpus\n",
    "def get_k_n_t_collocations(corpus_df, k, n, t, threshold, type):\n",
    "\n",
    "    #produce all collocations of length n\n",
    "    corpus_df['collocations'] = corpus_df['sentence_text'].apply(lambda x: generate_ngrams(x, n))\n",
    "\n",
    "    # place all collocations in a dictionary of structure <Collocation>: <Count>\n",
    "    collocation_counts = {}\n",
    "    for coll_list in corpus_df['collocations']:\n",
    "        for coll in coll_list:\n",
    "            collocation_counts[coll] = collocation_counts.get(coll, 0) + 1\n",
    "\n",
    "    if type == \"frequency\":\n",
    "        # only include collcations that appear more than <t>\n",
    "        filtered_collocations = {coll: count for coll, count in collocation_counts.items() if count >= t}\n",
    "    elif type == \"tfidf\":\n",
    "\n",
    "        total_docs = len(corpus_df['protocol_number'].unique())\n",
    "\n",
    "        # group by protocol numbers\n",
    "        grouped = corpus_df.groupby('protocol_number')\n",
    "        \n",
    "        corpus_collocations = [set(coll_list) for coll_list in corpus_df['collocations']]\n",
    "        idf_scores = compute_idf(corpus_collocations, total_docs)\n",
    "\n",
    "        tfidf_scores = {}\n",
    "\n",
    "        for protocol_number, group in grouped:\n",
    "            # Get all collocations in the current protocol\n",
    "            doc_collocations = [coll for coll_list in group['collocations'] for coll in coll_list]\n",
    "\n",
    "            tf_scores = compute_tf(doc_collocations, collocation_counts.keys())\n",
    "\n",
    "            # Compute TF-IDF for collocations in this document\n",
    "            tfidf = compute_tfidf(tf_scores, idf_scores)\n",
    "            for coll, score in tfidf.items():\n",
    "                tfidf_scores[coll] = tfidf_scores.get(coll, 0) + score\n",
    "\n",
    "        # Only include collocations that have a score >= t\n",
    "        filtered_collocations = {coll: score for coll, score in tfidf_scores.items() if score >= t}\n",
    "    else:\n",
    "        raise ValueError(\"Invalid type. Use 'frequency' or 'tfidf'.\")\n",
    "\n",
    "    sorted_collocations = sorted(filtered_collocations.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "    return sorted_collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = 'knesset_corpus.jsonl'\n",
    "output_file = 'top_collocations.txt'\n",
    "k = 10  # top 10 collocations\n",
    "n = 2   # bigrams\n",
    "t = 5   # minimum of <t> counts for an n-gram\n",
    "threshold = 0.1  # Minimum tf-idf score\n",
    "type = 'tfidf'\n",
    "\n",
    "#load corpus to df\n",
    "with open(corpus_path, 'r', encoding='utf-8') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "corpus_df = pd.DataFrame(data)\n",
    "\n",
    "result = get_k_n_t_collocations(corpus_df, k, n, t, threshold, type)\n",
    "\n",
    "#save the output into a file\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for collocation, score in result:\n",
    "        f.write(f\"{collocation}: {score}\\n\")\n",
    "\n",
    "print(\"Complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
