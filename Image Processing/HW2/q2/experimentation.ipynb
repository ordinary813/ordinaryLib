{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches is of (3|4 X 2 X 2) size. Each row is a match - pair of (kp1,kp2) where kpi = (x,y)\n",
    "def get_transform(matches, is_affine):\n",
    "    src_points, dst_points = matches[:,0], matches[:,1]\n",
    "\n",
    "    if is_affine:\n",
    "        T, _ = cv2.estimateAffinePartial2D(src_points, dst_points)\n",
    "    else:\n",
    "        T, _ = cv2.findHomography(src_points, dst_points, method=cv2.RANSAC)\n",
    "    return T\n",
    "\t\n",
    "\n",
    "def stitch(img1, img2):\n",
    "\t# Create a binary mask where img2 has non-zero pixels\n",
    "\tmask = (img2 > 0).any(axis=-1)  # Shape: (H, W)\n",
    "\n",
    "\t# Pad the mask to handle boundary conditions\n",
    "\tpadded_mask = np.pad(mask, ((1, 1), (1, 1)), mode='constant', constant_values=0)\n",
    "\n",
    "\t# Check the neighbors in the 3x3 region\n",
    "\tneighbor_mask = (\n",
    "\t\t\tpadded_mask[:-2, :-2] & padded_mask[:-2, 1:-1] & padded_mask[:-2, 2:] &  # Top row\n",
    "\t\t\tpadded_mask[1:-1, :-2] & padded_mask[1:-1, 1:-1] & padded_mask[1:-1, 2:] &  # Middle row\n",
    "\t\t\tpadded_mask[2:, :-2] & padded_mask[2:, 1:-1] & padded_mask[2:, 2:]  # Bottom row\n",
    "\t)\n",
    "\n",
    "\t# Combine the neighbor mask with the original mask\n",
    "\tvalid_mask = neighbor_mask & mask\n",
    "\n",
    "\t# Use the valid mask to prioritize img2\n",
    "\tstitched_image = np.where(valid_mask[..., None], img2, img1)\n",
    "\n",
    "\treturn stitched_image\n",
    "\n",
    "# Output size is (w,h)\n",
    "def inverse_transform_target_image(target_img, original_transform, output_size):\n",
    "    if original_transform.shape == (2, 3):      # Affine transformation\n",
    "        affine_transform = np.vstack([original_transform, [0,0,1]])\n",
    "        inverse_transform = np.linalg.inv(affine_transform)[:2, :]\n",
    "\n",
    "        warped_img = cv2.warpAffine(target_img, inverse_transform, output_size)\n",
    "    elif original_transform.shape == (3, 3):    # Homography\n",
    "        inverse_transform = np.linalg.inv(original_transform)\n",
    "        warped_img = cv2.warpPerspective(target_img, inverse_transform, output_size)\n",
    "    return warped_img\n",
    "\n",
    "# returns list of pieces file names\n",
    "def prepare_puzzle(puzzle_dir):\n",
    "\tedited = os.path.join(puzzle_dir, 'abs_pieces')\n",
    "\tif os.path.exists(edited):\n",
    "\t\tshutil.rmtree(edited)\n",
    "\tos.mkdir(edited)\n",
    "\t\n",
    "\taffine = 4 - int(\"affine\" in puzzle_dir)\n",
    "\t\n",
    "\tmatches_data = os.path.join(puzzle_dir, 'matches.txt')\n",
    "\tn_images = len(os.listdir(os.path.join(puzzle_dir, 'pieces')))\n",
    "\n",
    "\tmatches = np.loadtxt(matches_data, dtype=np.int64).reshape(n_images-1,affine,2,2)\n",
    "\t\n",
    "\treturn matches, affine == 3, n_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_transform(original_img, warped_img):\n",
    "    cv2.imshow(\"Original Image\", original_img)\n",
    "    cv2.imshow(\"Warped Image\", warped_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle_dir = 'puzzles/puzzle_homography_1'\n",
    "matches, is_affine, n = prepare_puzzle(puzzle_dir)\n",
    "img1 = cv2.imread(os.path.join(puzzle_dir, 'pieces/piece_1.jpg'))\n",
    "\n",
    "stitched_img = img1\n",
    "\n",
    "height, width = img1.shape[:2]\n",
    "output_size = (width, height)\n",
    "\n",
    "for i in range(max(1, n - 2)):\n",
    "    curr_matches = matches[i]\n",
    "    target_img = cv2.imread(os.path.join(puzzle_dir, 'pieces', f'piece_{i+2}.jpg'))\n",
    "    \n",
    "    transform = get_transform(curr_matches, is_affine)\n",
    "    warped_target = inverse_transform_target_image(target_img, transform, output_size)\n",
    "    \n",
    "    #DEBUG\n",
    "    #visualize_transform(target_img, warped_target)\n",
    "\n",
    "    stitched_img = stitch(stitched_img, warped_target)\n",
    "\n",
    "cv2.imwrite('stitched_image.jpg', stitched_img)\n",
    "cv2.imshow('Stitched Image', stitched_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
