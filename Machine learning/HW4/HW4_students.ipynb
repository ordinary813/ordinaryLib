{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBHBci_i2IgA"
      },
      "source": [
        "# Introducrtion to Machine Learning: Assignment #4\n",
        "## Submission date: 21\\03\\2024, 23:55.\n",
        "### Topics:\n",
        "- PCA\n",
        "- K means clustering\n",
        "- AdaBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGo4MrnG2NXa"
      },
      "source": [
        "Submitted by:\n",
        "\n",
        "Or Dinar 207035809"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eietFcHy2Kr2"
      },
      "source": [
        "**Assignment Instruction:**\n",
        "\n",
        "· Submissions in pairs only.\n",
        "\n",
        "· The code must be reasonably documented\n",
        "\n",
        "· Try to keep the code as clean, concise, and short as possible\n",
        "\n",
        "· Your submission must be entirely your own. Any attempts of plagiarism (including ChatGPT) will lead to disciplinary actions.\n",
        "\n",
        "· You should save a copy of the notebook to your Drive and answer all the questions inside the notebook, at the designated cells. Only the notebook will be submitted in moodle (in `.ipynb` format).\n",
        "\n",
        "· If you wish to work in your IDE, make a `.py` copy of the notebook, but as you finish insert the script back to the matching cells of the notebook.\n",
        "\n",
        "**Important:** All plots, results and outputs should be included in the notebook as the cells' outputs (run all cells and do not clear the output)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqPk-EK5tBJT"
      },
      "source": [
        "## Question 1 - Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i29PUS0e27qN"
      },
      "source": [
        "We learned in the tutorials about partitional clustering and specifically – k means algorithm. <br/>\n",
        "In this question you will implement it and see some nice applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTd61ral4Ju3"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NA919a0U4MFo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LiNstqG3peu"
      },
      "source": [
        "Complete the missing implementation of Kmeans. Since there are k clusters, we will label each point with {0,..,k-1}."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8ACpogUs4ux"
      },
      "outputs": [],
      "source": [
        "class Kmeans:\n",
        "\n",
        "\tdef __init__(self, n_clusters, max_iter=100, random_state=123):\n",
        "\t\tself.n_clusters = n_clusters\n",
        "\t\tself.max_iter = max_iter\n",
        "\t\tself.random_state = random_state\n",
        "\n",
        "\tdef initialize_centroids(self, X):\n",
        "\t\tnp.random.RandomState(self.random_state)\n",
        "\t\trandom_idx = np.random.permutation(X.shape[0])\n",
        "\t\tcentroids = X[random_idx[:self.n_clusters]]\n",
        "\t\treturn centroids\n",
        "\n",
        "\tdef reassign_centroids(self, X, labels):\n",
        "\t\tcentroids = np.zeros((self.n_clusters, X.shape[1]))\n",
        "\t\t# Implement here\n",
        "\t\treturn centroids\n",
        "\n",
        "\tdef compute_distance(self, X, centroids):\n",
        "\t\tdistance = np.zeros((X.shape[0], self.n_clusters))\n",
        "\t\tfor k in range(self.n_clusters):\n",
        "\t\t\trow_norm = np.linalg.norm(X - centroids[k, :], axis=1)\n",
        "\t\t\tdistance[:, k] = np.square(row_norm)\n",
        "\t\treturn distance\n",
        "\n",
        "\tdef find_closest_cluster(self, distance):\n",
        "\t\treturn np.argmin(distance, axis=1)\n",
        "\n",
        "\tdef compute_sse(self, X, labels, centroids):\n",
        "\t\tdistance = np.zeros(X.shape[0])\n",
        "\t\tfor k in range(self.n_clusters):\n",
        "\t\t\tdistance[labels == k] = np.linalg.norm(X[labels == k] - centroids[k], axis=1)\n",
        "\t\treturn np.sum(np.square(distance))\n",
        "\n",
        "\tdef fit(self, X):\n",
        "\t\tself.centroids = self.initialize_centroids(X)\n",
        "\t\tfor i in range(self.max_iter):\n",
        "\t\t\told_centroids = self.centroids\n",
        "\t\t\t# For each point, calculate distance to all k clustes.\n",
        "\t\t\tself.labels =\t# Assign the labels with closest distance' cluster.\n",
        "\t\t\tself.centroids = # Update the centroids\n",
        "\t\t\tif np.all(old_centroids == self.centroids):\n",
        "\t\t\t\tbreak\n",
        "\t\tself.error = self.compute_sse(X, self.labels, self.centroids)\n",
        "\n",
        "\tdef predict(self, X):\n",
        "\t\tdistance = self.compute_distance(X, self.centroids)\n",
        "\t\treturn self.find_closest_cluster(distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01SMbF1T6UVM"
      },
      "source": [
        "Load exams data, convert to numpy and plot it. <br/>\n",
        "The data can be found here: https://sharon.srworkspace.com/ml/datasets/hw4/exams.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVLM73H9vb69"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"https://sharon.srworkspace.com/ml/datasets/hw4/exams.csv\", header=None)\n",
        "data = data.to_numpy()\n",
        "\n",
        "x = data[:,:-1]\n",
        "y = data[:,-1]\n",
        "\n",
        "zero_labeled = x[y == 0]\n",
        "one_labeled = x[y == 1]\n",
        "\n",
        "# Scatter plot for label 0 (red)\n",
        "plt.scatter(zero_labeled[:, 0], zero_labeled[:, 1], color='red', label='y = 0', s=15)\n",
        "\n",
        "# Scatter plot for label 1 (blue)\n",
        "plt.scatter(one_labeled[:, 0], one_labeled[:, 1], color='blue', label='y = 1', s=15)\n",
        "\n",
        "# Set labels for each axis\n",
        "plt.xlabel('X1')\n",
        "plt.ylabel('X2')\n",
        "\n",
        "# Show legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3yHa5ap6k3W"
      },
      "source": [
        "We are going to divide the data into 2 clusters. <br/>\n",
        "Define Kmeans object and fit the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DV8XrX6AvdH-"
      },
      "outputs": [],
      "source": [
        "# Implement here\n",
        "\n",
        "# This code plots the clustered data with centroids\n",
        "labels = clust.labels\n",
        "centroids = clust.centroids\n",
        "\n",
        "c0 = data[labels == 0]\n",
        "c1 = data[labels == 1]\n",
        "\n",
        "plt.scatter(c0[:,0], c0[:,1], c='green', label='cluster 1')\n",
        "plt.scatter(c1[:,0], c1[:,1], c='blue', label='cluster 2')\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], marker='*', s=200, c='black', label='centroid')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn-tPolL8564"
      },
      "source": [
        "Use the Elbow Method to choose another number of centroids between 1-10. <br/>\n",
        "<font color='red'>Explain your choice</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3ebxS6y87C9"
      },
      "outputs": [],
      "source": [
        "sse = []\n",
        "list_k = list(range(1, 11))\n",
        "\n",
        "for k in list_k:\n",
        "  sse.append(error_of_current_clustering)\n",
        "\n",
        "'''Plot sse against k'''\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(list_k, sse, '-o')\n",
        "plt.xlabel(r'Number of clusters *k*')\n",
        "plt.ylabel('Sum of squared distance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbZZOx8W8BTS"
      },
      "source": [
        "Apply clustering with the selected k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR-GMy467BdZ"
      },
      "outputs": [],
      "source": [
        "# Implement here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbVNVuZo8ObI"
      },
      "source": [
        "Now, you will compress some image using k-means. <br/>\n",
        "Here, you are given image from size 400x600x3. The last parameter is the number of channels. 3 channels means that the image is colored (unlike 1 in, which is grayscale). <br/>\n",
        "Our goal is to reduce the number of colors to 20 and represent (compress) the photo using those 20 colors only. <br/>\n",
        "\n",
        "Motivation: the original image requires 400x600x3x8 bits, while the new image will require only 400x600x5 + 20x24 bits, almost 5 times smaller!<br/>\n",
        "To really do this, we will take the image and treat every pixel as a data point, where each data point is in 3d space (r,g,b). Then, we cluster into 20 centroids, and we assign each pixel to a centroid. This will allow us to represent the image using only 20 colors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoBZbtVnDkAS"
      },
      "source": [
        "### helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amsgotKeDmpa"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "def read_image(url):\n",
        "    req = urllib.request.urlopen(url)\n",
        "    arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
        "    return cv2.imdecode(arr, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tfm_EwY9QWy"
      },
      "source": [
        "Complete the missing code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoCzuvQqKogO"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import cv2\n",
        "\n",
        "img = read_image('https://sharon.srworkspace.com/ml/datasets/hw4/image.jpg')\n",
        "img_size = img.shape\n",
        "\n",
        "#Reshape it to be 2-dimension\n",
        "X = img.reshape(img_size[0] * img_size[1], img_size[2])\t\t# Turn hxwx3 into (h*w)x3\n",
        "\n",
        "# Run the Kmeans algorithm\n",
        "km = KMeans(n_clusters=20)\n",
        "km.fit(X)\n",
        "\n",
        "'''\n",
        "The km has the following properties:\n",
        "(*) km.labels_ is an array size (pixels, 20), will give each pixel its class from 20 classes (values are between 0-19)\n",
        "(*) km.cluster_centers_ is an array size 20x3, where the ith row represents the color value for the ith label.\n",
        "\tFor example, cluster_centers_[0] = [r,g,b], the first center.\n",
        "'''\n",
        "\n",
        "# Use the centroids to compress the image\n",
        "img_compressed = # Use cluster_centers_ and labels_\n",
        "img_compressed = np.clip(img_compressed.astype('uint8'), 0, 255)\n",
        "\n",
        "# Reshape X_recovered to have the same dimension as the original image 128 * 128 * 3'''\n",
        "img_compressed = img_compressed.reshape(img_size[0], img_size[1], img_size[2])\n",
        "\n",
        "# Plot the original and the compressed image next to each other'''\n",
        "fig, ax = plt.subplots(1, 2, figsize = (12, 8))\n",
        "\n",
        "ax[0].imshow(img)\n",
        "ax[0].set_title('Original Image')\n",
        "\n",
        "ax[1].imshow(img_compressed)\n",
        "ax[1].set_title(f'Compressed Image with {km.n_clusters} colors')\n",
        "\n",
        "for ax in fig.axes:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2lP4smNqbBa"
      },
      "source": [
        "## Question 2 - AdaBoost\n",
        "See attached pdf in moodle assignment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_iKlHnjsiBj"
      },
      "source": [
        "## load smiling dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhlIztf38_j3"
      },
      "source": [
        "In the rest of the assignment, we will deal with the Smiling-face dataset, which determines if a person is smiling or not. <br/>\n",
        "Your task is: run the following section and make sure your understand what's going on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq3cRhYC6AaA"
      },
      "source": [
        "Go to your <a href=\"https://www.kaggle.com/\">Kaggle</a> account and under the settings, generate new API token. <br/>\n",
        "This will give you the json file, which you will upload here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XsC3aagYU8Bg"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# The algorithm expects you to upload JSON file to it!\u001b[39;00m\n\u001b[0;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m pip install -q kaggle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      5\u001b[0m files\u001b[38;5;241m.\u001b[39mupload()\n\u001b[0;32m      6\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mkdir ~/.kaggle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "# The algorithm expects you to upload JSON file to it!\n",
        "\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets list\n",
        "! kaggle datasets download chazzer/smiling-or-not-face-data\n",
        "! unzip -q smiling-or-not-face-data.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB0zaNLzslMW"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V1j2in2zXhT0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UTtYOlw9eDa"
      },
      "source": [
        "process the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvQvtLOAXk8q"
      },
      "outputs": [],
      "source": [
        "def proccess_data(folder):\n",
        "  image_arrays = []\n",
        "  for filename in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, filename)\n",
        "    image = cv2.imread(file_path)\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image_arrays.append(gray_image)\n",
        "  return np.array(image_arrays)\n",
        "\n",
        "smile = proccess_data('./data/smile')\n",
        "non_smile = proccess_data('./data/non_smile')\n",
        "\n",
        "dataset = np.vstack((smile,non_smile))\n",
        "labels = np.concatenate((np.ones(smile.shape[0]),np.zeros(non_smile.shape[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nW9k369dhYT"
      },
      "source": [
        "display smiling and non-smiling image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfbqqhCadGRX"
      },
      "outputs": [],
      "source": [
        "plt.subplot(121)\n",
        "plt.title(\"Smile\")\n",
        "plt.imshow(smile[0], cmap='gray')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title(\"Not smile\")\n",
        "plt.imshow(non_smile[0], cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEVo_5-k990Z"
      },
      "source": [
        "print the smiling and non-smiling data + the united dataset along with labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hCqccgRZUzT"
      },
      "outputs": [],
      "source": [
        "print(f'smile array size is (images, height, width)={smile.shape}')\n",
        "print(f'non smile array size is (images, height, width)={non_smile.shape}')\n",
        "print()\n",
        "print(f'dataset array size is {dataset.shape}')\n",
        "print(f'labels array size is {labels.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw3w7aGusyDN"
      },
      "source": [
        "Prepear train and test datasets, print their structure. Since you have to deal with 1d features, we flatten the squared image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhyWZgWXbE4I"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataset, labels, test_size = 0.2, stratify=labels, random_state=42)\n",
        "\n",
        "print(f'train size is {x_train.shape} and labels size is {y_train.shape}')\n",
        "print(f'test size is {x_test.shape} and labels size is {y_test.shape}')\n",
        "print()\n",
        "\n",
        "x_train_flatten = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
        "x_test_flatten = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
        "\n",
        "print(f'flattened train size is {x_train_flatten.shape} ')\n",
        "print(f'flattened test size is {x_test_flatten.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scLdbLSYskMr"
      },
      "source": [
        "## Question 3 - PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0KjWT27q-kd"
      },
      "source": [
        "import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1tV-D9usq8eo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVPuhAjX-k9f"
      },
      "source": [
        "Implement PCA to reduce the dimension of the images from 4096=64x64 to 81=9x9. For time effciency, DONT use any loops here.\n",
        "\n",
        "Hint: Implement inverse_transform to recover the original vector from the compressed one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edDFB2MLcU4Q"
      },
      "outputs": [],
      "source": [
        "# shrinks the data matrix to have k features\n",
        "def PCA_train(data, k):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    Z = data - mean\n",
        "    scatter_mastrix = np.matmul(Z.transpose(), Z)\n",
        "    eigenvals, eigenvecs = np.linalg.eig(scatter_mastrix)\n",
        "    best_k_indices = np.argsort(eigenvals)[::-1][:k]\n",
        "    E = eigenvecs[:, best_k_indices].transpose()\n",
        "    y = np.matmul(E, Z.transpose())\n",
        "    return y\n",
        "    \n",
        "\n",
        "def PCA_test(test, mu, E):\n",
        "\t# Implement here\n",
        "\n",
        "def recover_PCA(data, mu, E):\n",
        "\t# Implement here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XGKa-V4ARsq"
      },
      "source": [
        "Apply the PCA. <br/>\n",
        "Make sure you fit the PCA model only to the training set (but apply it to both training and test sets). <br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jdtyXCLeGlx"
      },
      "outputs": [],
      "source": [
        "x_train_new, mu, eig = # Implement here\n",
        "x_test_new = # Implement here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OroYh4NAd6A"
      },
      "source": [
        "Pick another random image and show the result of applying PCA to it, and then try to recover the whole size again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US1NS8Mdf4ip"
      },
      "outputs": [],
      "source": [
        "plt.subplot(131)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(None, cmap='gray')\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.title(\"Image in lower dimension\")\n",
        "plt.imshow(None, cmap='gray')\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.title(\"Recovered Image\")\n",
        "plt.imshow(None, cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkI1iur3BDF4"
      },
      "source": [
        "Before training the model, use EIG_CDF, that given eigenvalues, draws a CDF of them like here:<br/><br/>\n",
        "\n",
        "![Picture1.jpg](https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcS3mOZk1x4X3ap9nuMnst5W5pMgOXF8r3Tmx1QcFX9mba_lleuB)\n",
        "\n",
        "As seen in the tutorials, we use them to see how much \"energy\" we preserve from the data. Use this to choose optimal dimension to reduce into, such the preserves 95% of the energy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-zaqczg_VGr"
      },
      "outputs": [],
      "source": [
        "def EIG_CDF(eig_list):\n",
        "\tsorted_eigenvalues = np.sort(eig_list)[::-1]\n",
        "\n",
        "\teigenvalues_cumsum = np.cumsum(sorted_eigenvalues)\n",
        "\n",
        "\teigenvalues_cumsum_normalized = eigenvalues_cumsum / eigenvalues_cumsum[-1]\n",
        "\tamount = # Implement here\n",
        "\n",
        "\tplt.plot(np.arange(1, len(sorted_eigenvalues)+1), eigenvalues_cumsum_normalized)\n",
        "\tplt.xlabel('Principal Component')\n",
        "\tplt.ylabel('Cumulative Proportion of Variance')\n",
        "\tplt.title(f'CDF of Eigenvalues - {amount} eigs preserves 95% of enetry')\n",
        "\tplt.show()\n",
        "\n",
        "# Call to EIG_CDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6nbAp0mBuqM"
      },
      "source": [
        "For the same image as before, show the result of applying PCA to it and recovering.<br/>\n",
        "Is the result better? What is different from 81 dimensions? <br/>\n",
        "<font color='red'>Write here your answer and explain it</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m7DAhXOCerg"
      },
      "outputs": [],
      "source": [
        "plt.subplot(131)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(None, cmap='gray')\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.title(\"Image in lower dimension\")\n",
        "plt.imshow(None, cmap='gray')\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.title(\"Recovered Image\")\n",
        "plt.imshow(None, cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqaVkkL6s1rE"
      },
      "source": [
        "Now, you are ready to train the model. Use KNN, tune the best k using cross_val_score (with sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNlJMtGYnh6T"
      },
      "outputs": [],
      "source": [
        "# Implement here\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(ks, accs)\n",
        "plt.xlabel('k')\n",
        "plt.xticks(ks)\n",
        "plt.ylabel('avg accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWqFTbTcC8d1"
      },
      "source": [
        "Print the accuracy of your model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvKlB4K3e7sD"
      },
      "outputs": [],
      "source": [
        "# Implement here\n",
        "print(f'acc on test is {acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVJW2S-vtDB3"
      },
      "source": [
        "Answer the following sum-up questions: <br/>\n",
        "- What pre-proccessing actions were done on the data?\n",
        "- Give two reasons for not applying Standard Scaler on this task.\n",
        "- Recall the KNN is using euclidian distance metric. Is it possible that switching distance metric will yield better result? What distance metric?\n",
        "\n",
        "<font color='red'>Write here your answers, with explainations</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k64rbQLVuhN1"
      },
      "source": [
        "## Question 4 - 10 points bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sakpw3-xumks"
      },
      "source": [
        "4 points - Use KNN with the metric that you answered that will be the best. Find the best possible k and print the accuracy test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp7u5_Hbvm10"
      },
      "outputs": [],
      "source": [
        "# Input: x, y with d features.\n",
        "# Output: the distance between them by the chosen metric.\n",
        "\n",
        "def Your_Metric(x, y):\n",
        "  # Implement here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbUt04yt4vnq"
      },
      "source": [
        "Print the accuracy of your model on the test set. Were you correct? If no, why do you think it happened? What else could be done? <br/>\n",
        "\n",
        "<font color='red'>Write here your answer</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypNpPPXK4vUS"
      },
      "outputs": [],
      "source": [
        "# Implement here\n",
        "print(f'acc on test is {acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn8CO-3t5Dfr"
      },
      "source": [
        "6 points - make the best model that you can, using all the models we have seen through this course. <br/>\n",
        "<font color='red'>Write here all your decisions you made and the motivation behind them.</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWohafKZ5Zog"
      },
      "outputs": [],
      "source": [
        "# Implement here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "wqPk-EK5tBJT",
        "d_iKlHnjsiBj",
        "scLdbLSYskMr",
        "k64rbQLVuhN1"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
