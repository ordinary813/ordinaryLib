{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Retrieve the song data from the file provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = pd.read_csv('Songs.csv', header = 0)\n",
    "songs_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Each entry ends with something like '1EmbedShare URLCopyEmbedCopy', so we removed those appearances from the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df['Lyrics'] = songs_df['Lyrics'].str.replace(r'\\d+EmbedShare URLCopyEmbedCopy$', \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Show all unique artists in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in songs_df['Artist'].unique():\n",
    "    print(f'{artist}: {songs_df[songs_df['Artist'] == artist].shape[0]} Songs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The dataset's size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The dataset contains {len(songs_df)} entries for songs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The dataset contains 3 duplicates so we will need to take care of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The dataset contains {len(songs_df['Title'].unique())} unique songs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cleanup of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = songs_df.drop_duplicates(subset='Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in songs_df['Artist'].unique():\n",
    "    print(f'{artist}: {songs_df[songs_df['Artist'] == artist].shape[0]} Songs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Average song length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = songs_df['Lyrics'].apply(lambda x: len(x.split()))\n",
    "avg_words = lengths.sum() / songs_df['Lyrics'].nunique()\n",
    "\n",
    "char_lengths = songs_df['Lyrics'].apply(lambda x: len(x))\n",
    "avg_chars = char_lengths.sum() / songs_df['Lyrics'].nunique()\n",
    "\n",
    "print(f'The average number of words in a song is {avg_words:.2f}')\n",
    "print(f'The average number of characters in a song is {avg_chars:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all lyrics into one large text\n",
    "all_lyrics = \" \".join(songs_df[\"Lyrics\"].dropna())\n",
    "\n",
    "# Clean the text (remove punctuation, convert to lowercase)\n",
    "all_lyrics = re.sub(r\"[^\\w\\s]\", \"\", all_lyrics.lower())\n",
    "\n",
    "# Tokenization\n",
    "words = all_lyrics.split()\n",
    "\n",
    "# Retrieve word frequencies\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# 3 most common words\n",
    "print(\"The 3 most common words are:\")\n",
    "for word, count in word_counts.most_common(3):\n",
    "    print(f\"{word}: {count} appearances\")\n",
    "\n",
    "# Definition of wordCloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\", colormap='plasma', max_words=50).generate_from_frequencies(word_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = songs_df[\"Lyrics\"].dropna().str.lower()\n",
    "\n",
    "# Tokenization the lyrics removing puncuation\n",
    "tokenized_lyrics = [re.findall(r\"\\b\\w+\\b|\\n\", lyric) for lyric in lyrics]\n",
    "\n",
    "# Build vocabulary\n",
    "word_counts = Counter(word for song in tokenized_lyrics for word in song)\n",
    "word_to_index = {word: i + 1 for i, (word, _) in enumerate(word_counts.items())}  # Start index from 1\n",
    "index_to_word = {i: word for word, i in word_to_index.items()}\n",
    "\n",
    "# Convert lyrics to numerical sequences\n",
    "encoded_sequences = [[word_to_index[word] for word in song if word in word_to_index] for song in tokenized_lyrics]\n",
    "\n",
    "# Vocabulary size\n",
    "vocab_size = len(word_to_index) + 1  # Adding 1 for padding if needed\n",
    "\n",
    "print(f\"Vocabulary Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sequence length (choose a reasonable length)\n",
    "SEQ_LENGTH = 10\n",
    "\n",
    "# Create input-target pairs\n",
    "input_sequences = []\n",
    "targets = []\n",
    "\n",
    "for song in encoded_sequences:\n",
    "    for i in range(1, len(song)):\n",
    "        n_gram_sequence = song[:i+1]  # Create sequence up to current word\n",
    "        if len(n_gram_sequence) >= 2:  # Ensure sequence has at least one input and one target\n",
    "            input_sequences.append(n_gram_sequence[:-1])  # All but last word (input)\n",
    "            targets.append(n_gram_sequence[-1])  # Last word (target)\n",
    "\n",
    "# Pad sequences to the same length\n",
    "max_seq_length = SEQ_LENGTH  # Set fixed sequence length\n",
    "padded_sequences = [([0] * (max_seq_length - len(seq)) + seq)[-max_seq_length:] for seq in input_sequences]\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(padded_sequences, dtype=torch.long)\n",
    "y = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "# PyTorch Dataset\n",
    "class SongLyricsDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = SongLyricsDataset(X, y)\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(f\"Dataset Size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=256, num_layers=4):\n",
    "        super(LyricsLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Convert word indices to embeddings\n",
    "        lstm_out, _ = self.lstm(x)  # LSTM forward pass\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Get output from last LSTM step\n",
    "        return out\n",
    "\n",
    "# Model setup\n",
    "model = LyricsLSTM(vocab_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_X, batch_y in data_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_X)\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(data_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LyricsGenerator(starting_string, model, word_to_index, index_to_word, max_words=avg_words):\n",
    "    model.eval()\n",
    "    max_words = int(max_words)\n",
    "    \n",
    "    if not starting_string.strip():\n",
    "        starting_word = random.choice(list(word_to_index.keys()))\n",
    "        words = [starting_word]\n",
    "    else:\n",
    "        words = starting_string.lower().split()\n",
    "    \n",
    "    for _ in range(max_words):\n",
    "        # Convert words to indices\n",
    "        encoded_input = [word_to_index.get(word, 0) for word in words][-SEQ_LENGTH:]\n",
    "        input_tensor = torch.tensor([encoded_input], dtype=torch.long).to(device)\n",
    "\n",
    "        # Predict next word\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            predicted_index = torch.argmax(output, dim=1).item()\n",
    "\n",
    "        # Convert index to word\n",
    "        next_word = index_to_word.get(predicted_index, \"<UNK>\")\n",
    "        words.append(next_word)\n",
    "\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"it's not a silly little moment\"\n",
    "generated_text = LyricsGenerator(seed, model, word_to_index, index_to_word)\n",
    "print(\"\\nGenerated Lyrics:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"There is a house\"\n",
    "generated_text = LyricsGenerator(seed, model, word_to_index, index_to_word)\n",
    "print(\"\\nGenerated Lyrics:\\n\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = \"\"\n",
    "generated_text = LyricsGenerator(seed, model, word_to_index, index_to_word)\n",
    "print(\"\\nGenerated Lyrics:\\n\", generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
